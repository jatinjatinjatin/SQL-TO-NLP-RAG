ğŸ§  NLP â†’ SQL Agent with Schema RAG, Streaming & Evaluation

An end-to-end LLM-powered NLP-to-SQL system that converts natural language questions into executable SQL using schema-aware Retrieval-Augmented Generation (RAG), validates queries through execution, streams responses, and provides automatic evaluation with confidence scoring and dashboards.

âœ¨ Key Features

ğŸ”¤ Natural Language â†’ SQL using LLMs (Ollama / LLaMA)

ğŸ§© Schema-Aware RAG to ground SQL generation in database structure

âš™ï¸ Automatic SQL Execution & Healing

ğŸ” Streaming SQL & Results (real-time feedback)

ğŸ“Š Confidence Score per Answer

ğŸ§ª Automated Evaluation Harness with expected SQL

ğŸ“ˆ Evaluation Dashboard (accuracy, execution success, latency)

ğŸ¨ Animated UI with Streamlit + GSAP + Three.js

ğŸ§  Research-ready architecture (clean, modular, extensible)

ğŸ—ï¸ Architecture Overview

User Question
     â†“
Streamlit UI (GSAP + Three.js)
     â†“
FastAPI Backend
     â†“
Schema RAG (Vector Search over DB schema)
     â†“
LLM (NLP â†’ SQL)
     â†“
SQL Validation & Healing
     â†“
Database Execution (SQLite)
     â†“
Results + Confidence Score
     â†“
Evaluation Dashboard

ğŸ“ Project Structure
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                # FastAPI entrypoint
â”‚   â”œâ”€â”€ sql_engine.py         # SQL generation & execution
â”‚   â”œâ”€â”€ schema_rag.py         # Schema retrieval (RAG)
â”‚   â”œâ”€â”€ database.py           # SQLite connection
â”‚   â”œâ”€â”€ seed.py               # Database seeding
â”‚   â”œâ”€â”€ evaluation.py         # Test harness & metrics
â”‚   â””â”€â”€ models.py             # Confidence scoring logic
â”‚
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ app.py                # Streamlit UI
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ app.db                # SQLite database
â”‚
â””â”€â”€ README.md

âš™ï¸ Tech Stack
Layer	    Tools
LLM -->	 Ollama (LLaMA)
Backend -->	 FastAPI
Frontend -->	 Streamlit
RAG	   --> LangChain + Vector Embeddings
Database	 --> SQLite
Animation -->	GSAP, Three.js
Evaluation	--> Python (custom harness)


ğŸš€ Getting Started

1ï¸âƒ£ Create Virtual Environment
python -m venv .venv
.venv\Scripts\activate   # Windows

2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

3ï¸âƒ£ Seed the Database
python backend/seed.py

4ï¸âƒ£ Start Backend (FastAPI)
uvicorn backend.app:app --reload

5ï¸âƒ£ Start Frontend (Streamlit)
streamlit run frontend/app.py

ğŸ§ª Example Queries to Try

Show all customers

Total sales per customer

Which customer has the highest order value?

List orders placed in the last 30 days

Average order value by customer

ğŸ“Š Automatic Evaluation System

âœ” What Gets Evaluated

SQL correctness

Execution success

Schema grounding

Latency

Confidence score alignment

ğŸ§ª Test Harness

Each test includes:

{
  "question": "Total sales per customer",
  "expected_sql": "SELECT customer_id, SUM(amount) FROM orders GROUP BY customer_id"
}

ğŸ“ˆ Metrics Produced

Accuracy (%)

Execution Success Rate

Avg Latency

Confidence Calibration

ğŸ§  Confidence Scoring

Each response includes a confidence score based on:

Schema match quality

SQL execution success

LLM consistency

Result stability

Example:

{
  "sql": "...",
  "result": [...],
  "confidence": 0.87
}

ğŸ“¡ Streaming Support

SQL generation streamed token-by-token

Results streamed row-by-row

Improves transparency and UX

ğŸ”¬ Research Contributions

Practical schema-grounded NLP-to-SQL

Execution-based validation loop

Confidence-aware LLM outputs

End-to-end evaluation pipeline

UI transparency with streaming

ğŸ”® Future Work

Multi-database support (Postgres, MySQL)

Hallucination detection metrics
